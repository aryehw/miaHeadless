{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# select one of the multiple GPU cards on the server.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # set GPU if multiple present\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  unetDensnet201_2023-01-24_08-17-37\n"
     ]
    }
   ],
   "source": [
    "# the pkl directory contins the pkl files that hold a DeepLearning structure that defines the DL model\n",
    "pklDir = input('Enter pkl path or use default\\n') or '/media/amw/TOSHIBA EXT/alerding/models/pkl/'\n",
    "# the model directory will receive the trained model\n",
    "modelDir = input('Enter model output directory or default\\n') or '/media/amw/TOSHIBA EXT/alerding/models/gpuModels/'\n",
    "    \n",
    "loadweights = None\n",
    "\n",
    "# modelname is the name of hte pkl file without its pkl  extension.\n",
    "# a pkl file holds a data structure or object. IN this case, it is expected to hold a DeepLearning object that was saved\n",
    "# using File>Save DL Object... in mianalyzer. \n",
    "modelname = input(\"Enter modelname without extension or use default\") or \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "\n",
    "\n",
    "numclasses = 4\n",
    "\n",
    "# trainingdata is a directory that holds the annotated images. The labels must be in trainingdata/Segmentation_labels/\n",
    "# and they must be npz files.\n",
    "trainingdata = '/media/amw/TOSHIBA EXT/alerding/annotated/notCroppedLabels2/resized/'\n",
    "validationdata = None\n",
    "\n",
    "print(\"model: \", modelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is left from the version that reads the dl object from a pkl file.\n",
    "Now that the  dl structure can be defined in the code, it is not required.\n",
    "'''\n",
    "\n",
    "print('load settings')\n",
    "#filehandler = open(modelname + '.pkl', 'rb')\n",
    "filehandler = open(pklDir + modelname + '.pkl', 'rb')\n",
    "\n",
    "dl = pickle.load(filehandler)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(vars(dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates the dl object. Default is UNet, resnet152, 100 epochs,\n",
    "scaleFactor is 0.5, and learning rate is 0.001.\n",
    "All the other parmeters are the defaults of the dl object.\n",
    "'''\n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "from dl.DeepLearning import *\n",
    "def createDL( epochs=100, scaleFactor=0.5, learning_rate = 0.001):\n",
    "    dl = DeepLearning()\n",
    "    dl.Epochs = epochs\n",
    "    dl.ImageScaleFactor = scaleFactor\n",
    "#    dl.Mode = Segmentation()\n",
    "    dl.learning_rate = learning_rate\n",
    "    dl.Mode.architecture = 'UNet'\n",
    "    dl.Mode.backbone = 'resnet152'\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create the dl object and verify that it is initialized. \n",
    "'''\n",
    "\n",
    "dl = createDL( epochs=50, scaleFactor=0.5, learning_rate = 0.002)\n",
    "\n",
    "# pod, stem, background, and unlabeled (for deleaved soybean plants)\n",
    "numClasses =4\n",
    "\n",
    "print('init model')\n",
    "dl.initModel(numclasses)\n",
    "\n",
    "dl.Model = dl.Mode.getModel(numClasses, 3)\n",
    "\n",
    "print('load model')\n",
    "if loadweights is not None:\n",
    "    dl.Model.load_weights(loadweights)\n",
    "\n",
    "print(dl.initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we  do the training\n",
    "'''\n",
    "        \n",
    "if dl.initialized:\n",
    "    print('start training')\n",
    "    dl.initData_StartTraining(trainingdata, validationdata)\n",
    "    print('training finished')\n",
    "else:\n",
    "    print('could not initialize model')\n",
    "            \n",
    "print('saving weights')\n",
    "dl.Model.save_weights(modelDir+modelname + '.h5')\n",
    "print('saving training data')\n",
    "dl.saveTrainingRecord(modelDir+modelname +'.csv')\n",
    "#   print('saving model')\n",
    "#   dl.Model.save(modelDir+'full')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell does a prediction on a directory of jpg images (could be any type, but that is what I have).\n",
    "# predictionFolder contains the images which ill be predicted, and a subdirectory with eh modelname will be created\n",
    "# to hold the predicted segmentation.\n",
    "\n",
    "predictionFolder = input('Enter folder for prediction or use default\\n')  or '/home/dsi/aryeh/data/plants/Harvest8Orange5_7Oct17/'\n",
    "outputPath = predictionFolder + modelname+'_ep'+str(dl.epochs)+'/'\n",
    "try:\n",
    "    os.mkdir(outputPath)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "files = glob.glob(predictionFolder + '*.jpg')\n",
    "print(len(files))\n",
    "\n",
    "# If we do not want to process the entire folder, we can limit the number of processed image to count. \n",
    "count = 0\n",
    "for i in files:\n",
    "    print(i)\n",
    "    img = cv2.imread(i)\n",
    "    prediction = dl.Mode.PredictImage(img)\n",
    "    plt.figure(count)\n",
    "    plt.imshow(prediction)\n",
    "    plt.show()\n",
    "    cv2.imwrite(outputPath+'segmented_'+os.path.basename(i).replace('jpg', 'png'), prediction)\n",
    "    count += 1\n",
    "    if count > 1:\n",
    "       break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was checking why repeated runs of the prediction produced different reauslts. One possibility is that\n",
    "# I need to reset the DL object between runs. But I am not sure about this.\n",
    "print(dl.Model)\n",
    "dl.cleanMemory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
