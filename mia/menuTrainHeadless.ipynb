{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is meant to run mianalyzer headless. Mianalyzer is a code that can run a variety of neural network architrecture and backbones, without the user having ot define them himeself. It normally runs as a GUI application. However, when run on a remote server, the GUI version is much too slow,  The mianalyzer author (koerber) kindly provided a python script to run the training sequence  headless, after loading a \"pickled\"dl object from a pkl file. \n",
    "\n",
    "Inputs:\n",
    "    1. Directory that holds the pkl file\n",
    "    2. Directory where the model will be saved\n",
    "    3. The name of the saved pkl file (the pkl extensionis assumed)\n",
    "    4. The directory containing the training data. The Segmentation_labels subdiretory must also be present.\n",
    "    5. The prediction folder containing images on which the trained model will be tested. \n",
    "    6. model backbone (default is densenet201)\n",
    "    7. number of epochs (default defined in the pkl file)\n",
    "\n",
    " Outputs:\n",
    "    1. The dl object that will be used to train the model\n",
    "    2. The trained model (a .h5 file, and a .csv file with the loss history)\n",
    "    3. A subdirectory that will hold the segmented images.\n",
    "\n",
    "This Jupyter script is based on code provided by mianalzer author Nils Koerber (nils.koerber@bfr.bund.de)\n",
    "\n",
    "Modifed by Aryeh Weiss\n",
    "Last modified: 19 June 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the script usees tkinter to prompt for teh various directories and files that are needed.\n",
    "The defaults are the same, and cliking ok will select default values.\n",
    "When run on a remote GPU server, this version will be slower because it opens X windows on the local machine,\n",
    "pver the network.\n",
    "\n",
    "TODO: 1. Add a drop down menu for all of the possible backbones.\n",
    "      2. Change default backone to be that of teh pkl file (currenlty it is densenet201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# select one of the multiple GPU cards on the server.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # set GPU if multiple present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsigpu04\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code is developed and run on at least two machines\n",
    "Here we setup the default paths for each machine.\n",
    "Eventually we must find a more general way to do this.\n",
    "'''\n",
    "\n",
    "host = os.getenv('HOSTNAME')\n",
    "if host==None:      # pop os dees not have HOSTNAME defined by default.\n",
    "    host = \"pop\"\n",
    "print(host)\n",
    "\n",
    "if \"dsigpu\" in host:\n",
    "    pklDir = '/home/dsi/aryeh/data/mia/pkl/'\n",
    "    modelDir = '/home/dsi/aryeh/data/mia/trained_models/'\n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata = '/home/dsi/aryeh/data/plants/unCropped/resized/'\n",
    "    predictionFolder = '/home/dsi/aryeh/data/plants/Harvest8Orange5_7Oct17/'\n",
    "elif \"pop\" in host:\n",
    "    pklDir = '/media/amw/TOSHIBA EXT/alerding/models/pkl/'\n",
    "    modelDir = '/media/amw/TOSHIBA EXT/alerding/models/gpuModels/'\n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata =  '/media/amw/TOSHIBA EXT/alerding/annotated/notCroppedLabels2/resized/'\n",
    "    predictionFolder = '/media/amw/TOSHIBA EXT/alerding/Harvest 8 Orange 5,7 Oct 17.r/vertical/'\n",
    "else:\n",
    "    pklDir = None\n",
    "    modelDir = None \n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata = None\n",
    "    predictionFolder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  UNet_seresnext101_ep100\n"
     ]
    }
   ],
   "source": [
    "os.environ['DISPLAY']='localhost:10.0'\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog as fd\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "pklDir = fd.askdirectory(initialdir=pklDir) + os.sep\n",
    "modelDir = fd.askdirectory(initialdir=modelDir) + os.sep\n",
    "trainingdata = fd.askdirectory(initialdir=trainingdata) + os.sep\n",
    "predictionFolder = fd.askdirectory(initialdir=predictionFolder) + os.sep\n",
    "\n",
    "modelFilePath = fd.askopenfilename(\n",
    "        title='Open a pkl file',\n",
    "        initialdir=pklDir)\n",
    "\n",
    "filename = os.path.basename(modelFilePath)\n",
    "modelname = os.path.splitext(filename)[0]\n",
    "\n",
    "print(\"model: \", modelname)\n",
    "\n",
    "# it would be a good idea to collect all of the legitimate backbones and display them in a drop down menu.\n",
    "BackBone = input(\"input backbone or enter for default\\n\") or None\n",
    "\n",
    "strEpochs = input(\"input number of epochs or enter to use the predefined value in a pkl file\\n\") or '0'\n",
    "epochs = int(strEpochs)\n",
    "\n",
    "validationdata = None\n",
    "\n",
    "loadweights = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load settings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 07:30:57.376324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "{'architecture': 'UNet',\n",
      " 'backbone': 'seresnext101',\n",
      " 'loss': <dl.loss.segmentation_losses.SegmentationLosses object at 0x7f567d8295d0>,\n",
      " 'metric': <dl.metric.segmentation_metrics.SegmentationMetrics object at 0x7f567d8293d0>,\n",
      " 'parent': <dl.DeepLearning.DeepLearning object at 0x7f56c91e41d0>,\n",
      " 'preprocessingfnc': None,\n",
      " 'pretrained': True,\n",
      " 'type': <dlMode.Segmentation: 2>}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is from the version that reads the dl object from a pkl file.\n",
    "'''\n",
    "\n",
    "print('load settings')\n",
    "#filehandler = open(modelname + '.pkl', 'rb')\n",
    "filehandler = open(pklDir + modelname + '.pkl', 'rb')\n",
    "\n",
    "dl = pickle.load(filehandler)\n",
    "print(dl.epochs)\n",
    "if epochs != 0:\n",
    "    dl.epochs = epochs\n",
    "if BackBone != None:\n",
    "    dl.Mode.backbone = BackBone\n",
    "pprint(vars(dl.Mode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run this cell if you want to save the dl object as a pkl file\n",
    "'''\n",
    "\n",
    "pklFileHandler = open(pklDir+dl.Mode.architecture+'_'+dl.Mode.backbone+'_ep'+str(dl.epochs) + '.pkl','wb')\n",
    "#import sys\n",
    "#print(sys.getrecursionlimit())\n",
    "#sys.setrecursionlimit(4*sys.getrecursionlimit())\n",
    "#print(sys.getrecursionlimit())\n",
    "\n",
    "hed = dl.hed\n",
    "dl.hed = None\n",
    "model = dl.Model\n",
    "dl.Model = None\n",
    "pickle.dump(dl, pklFileHandler)\n",
    "dl.hed = hed\n",
    "dl.Model = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 07:31:26.258974: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-19 07:31:26.267032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-19 07:31:27.721020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2023-06-19 07:31:27.721075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-19 07:31:27.733181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-19 07:31:27.733243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-19 07:31:27.738298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-19 07:31:27.741146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-19 07:31:27.748550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-19 07:31:27.752993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-19 07:31:27.762676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-19 07:31:28.011128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-06-19 07:31:28.013077: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-19 07:31:28.020016: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-19 07:31:28.072737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2023-06-19 07:31:28.072858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-19 07:31:28.072934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-19 07:31:28.072979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-19 07:31:28.073019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-19 07:31:28.073060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-19 07:31:28.073101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-19 07:31:28.073140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-19 07:31:28.073181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-19 07:31:28.077235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-06-19 07:31:28.077313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-19 07:31:28.798202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-19 07:31:28.798249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-06-19 07:31:28.798263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-06-19 07:31:28.801241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10271 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# pod, stem, background, and unlabeled (for deleaved soybean plants)\n",
    "numClasses =4\n",
    "\n",
    "print('init model')\n",
    "dl.initModel(numClasses)\n",
    "\n",
    "dl.Model = dl.Mode.getModel(numClasses, 3)\n",
    "\n",
    "print('load model')\n",
    "if loadweights is not None:\n",
    "    dl.Model.load_weights(loadweights)\n",
    "\n",
    "print(dl.initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we  do the training\n",
    "'''\n",
    "        \n",
    "if dl.initialized:\n",
    "    print('start training')\n",
    "    dl.initData_StartTraining(trainingdata, validationdata)\n",
    "    print('training finished')\n",
    "else:\n",
    "    print('could not initialize model')\n",
    "            \n",
    "print('saving weights')\n",
    "modelname=dl.Mode.architecture+'_'+dl.Mode.backbone\n",
    "dl.Model.save_weights(modelDir+modelname+'_ep'+str(dl.epochs) + '.h5')\n",
    "print('saving training data')\n",
    "dl.saveTrainingRecord(modelDir+modelname+'_ep'+str(dl.epochs) +'.csv')\n",
    "#   print('saving model')\n",
    "#   dl.Model.save(modelDir+'full')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell does a prediction on a directory of jpg images (could be any type, but that is what I have).\n",
    "# predictionFolder contains the images which ill be predicted, and a subdirectory with the modelname will be created\n",
    "# to hold the predicted segmentation.\n",
    "\n",
    "predictionFolder = fd.askdirectory(initialdir=predictionFolder) + os.sep\n",
    "outputPath = predictionFolder + modelname+'_ep'+str(dl.epochs)+'/'\n",
    "try:\n",
    "    os.mkdir(outputPath)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "files = glob.glob(predictionFolder + '*.jpg')\n",
    "print(len(files))\n",
    "\n",
    "# If we do not want to process the entire folder, we can limit the number of processed image to count. \n",
    "# If the entire folder is processed, then it wold be agood idea to comment out the image display \n",
    "count = 0\n",
    "for i in files:\n",
    "    print(i)\n",
    "    img = cv2.imread(i)\n",
    "    prediction = dl.Mode.PredictImage(img)\n",
    "    plt.figure(count)\n",
    "    plt.imshow(prediction)\n",
    "    plt.show()\n",
    "    cv2.imwrite(outputPath+'segmented_'+os.path.basename(i).replace('jpg', 'png'), prediction)\n",
    "    count += 1\n",
    "#    if count > 10:\n",
    "#       break\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
