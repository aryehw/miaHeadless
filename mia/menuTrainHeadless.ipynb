{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is meant to run mianalyzer headless. Mianalyzer is a code that can run a variety of neural network architrecture and backbones, without the user having ot define them himeself. It normally runs as a GUI application. However, when run on a remote server, the GUI version is much too slow,  The mianalyzer author (koerber) kindly provided a python script to run the training sequence  headless, after loading a \"pickled\"dl object from a pkl file. \n",
    "\n",
    "Inputs:\n",
    "    1. Directory that holds the pkl file\n",
    "    2. Directory where the model will be saved\n",
    "    3. The name of the saved pkl file (the pkl extensionis assumed)\n",
    "    4. The directory containing the training data. The Segmentation_labels subdiretory must also be present.\n",
    "    5. The prediction folder containing images on which the trained model will be tested. \n",
    "    6. model backbone (default is densenet201)\n",
    "    7. number of epochs (default defined in the pkl file)\n",
    "\n",
    " Outputs:\n",
    "    1. The dl object that will be used to train the model\n",
    "    2. The trained model (a .h5 file, and a .csv file with the loss history)\n",
    "    3. A subdirectory that will hold the segmented images.\n",
    "\n",
    "This Jupyter script is based on code provided by mianalzer author Nils Koerber (nils.koerber@bfr.bund.de)\n",
    "\n",
    "Modifed by Aryeh Weiss\n",
    "Last modified: 19 June 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the script usees tkinter to prompt for teh various directories and files that are needed.\n",
    "The defaults are the same, and cliking ok will select default values.\n",
    "When run on a remote GPU server, this version will be slower because it opens X windows on the local machine,\n",
    "pver the network.\n",
    "\n",
    "TODO: 1. Add a drop down menu for all of the possible backbones.\n",
    "      2. Change default backone to be that of teh pkl file (currenlty it is densenet201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog as fd\n",
    "\n",
    "\n",
    "# select one of the multiple GPU cards on the server.\n",
    "gpuNumber = input(\"Select GPU or enter for 0\\n\") or '0'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpuNumber  # set GPU if multiple present\n",
    "\n",
    "os.environ['DISPLAY']='localhost:10.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsigpu02\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code is developed and run on at least two machines\n",
    "Here we setup the default paths for each machine.\n",
    "Eventually we must find a more general way to do this.\n",
    "'''\n",
    "\n",
    "host = os.getenv('HOSTNAME')\n",
    "if host==None:      # pop os dees not have HOSTNAME defined by default.\n",
    "    host = \"pop\"\n",
    "print(host)\n",
    "\n",
    "if \"dsigpu\" in host:\n",
    "    pklDir = '/home/dsi/aryeh/data/mia/pkl/'\n",
    "    modelDir = '/home/dsi/aryeh/data/mia/trained_models/'\n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata = '/home/dsi/aryeh/data/plants/unCropped/resized/'\n",
    "    predictionFolder = '/home/dsi/aryeh/data/plants/Harvest8Orange5_7Oct17/'\n",
    "elif \"pop\" in host:\n",
    "    pklDir = '/media/amw/TOSHIBA EXT/alerding/models/pkl/'\n",
    "    modelDir = '/media/amw/TOSHIBA EXT/alerding/models/gpuModels/'\n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata =  '/media/amw/TOSHIBA EXT/alerding/annotated/notCroppedLabels2/resized/'\n",
    "    predictionFolder = '/media/amw/TOSHIBA EXT/alerding/Harvest 8 Orange 5,7 Oct 17.r/vertical/'\n",
    "else:\n",
    "    pklDir = None\n",
    "    modelDir = None \n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata = None\n",
    "    predictionFolder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Put this in a separate cell so that multiple instances of Tk are not invoked\n",
    "'''\n",
    "root = Tk()\n",
    "root.withdraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  unetDensenet201ep75_221108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pklDir = fd.askdirectory(initialdir=pklDir) + os.sep\n",
    "modelDir = fd.askdirectory(initialdir=modelDir) + os.sep\n",
    "trainingdata = fd.askdirectory(initialdir=trainingdata) + os.sep\n",
    "predictionFolder = fd.askdirectory(initialdir=predictionFolder) + os.sep\n",
    "\n",
    "\n",
    "\n",
    "modelFilePath = fd.askopenfilename(\n",
    "        title='Open a pkl file',\n",
    "        initialdir=pklDir)\n",
    "\n",
    "filename = os.path.basename(modelFilePath)\n",
    "modelname = os.path.splitext(filename)[0]\n",
    "\n",
    "print(\"model: \", modelname)\n",
    "\n",
    "validationdata = None\n",
    "\n",
    "loadweights = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Set the window geometry\n",
    "root.geometry(\"200x200\")\n",
    "root.deiconify()\n",
    "\n",
    "# Create object\n",
    "# root = Tk()\n",
    "\n",
    "# Adjust size\n",
    "# root.geometry( \"200x200\" )\n",
    "\n",
    "# Change the label text\n",
    "def show():\n",
    "\tlabel.config( text = clicked.get() )\n",
    "\n",
    "# list of backbones\n",
    "backbones = [None, 'resnet18', 'resnet34','resnet50', 'resnet101', 'resnet152',\n",
    "             'seresnet18', 'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', 'seresnext101',\n",
    "             'senet154','resnext50', 'resnext101', 'vgg16', 'vgg19',\n",
    "             'densenet121', 'densenet169', 'densenet201', 'inceptionresnetv2', 'inceptionv3',\n",
    "             'mobilenet', 'mobilenetv2',\n",
    "             'efficientnetb0','efficientnetb1','efficientnetb02','efficientnetb3','efficientnetb4','efficientnetb5','efficientnetb6','efficientnetb7']\n",
    "\n",
    "# datatype of menu text\n",
    "clicked = StringVar()\n",
    "\n",
    "# Create Dropdown menu\n",
    "drop = OptionMenu( root , clicked , *backbones )\n",
    "drop.pack()\n",
    "\n",
    "# Create Label\n",
    "label = Label( root , text = \"Choose backbone\" )\n",
    "label.pack()\n",
    "\n",
    "Button(root, text=\"Quit\", command=root.destroy).pack() \n",
    "  \n",
    "# Execute tkinter\n",
    "root.mainloop()\n",
    "\n",
    "BackBone = clicked.get()\n",
    "print(BackBone)\n",
    "\n",
    "strEpochs = input(\"input number of epochs or enter to use the predefined value in a pkl file\\n\") or '0'\n",
    "epochs = int(strEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load settings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 17:44:51.382892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "{'architecture': 'UNet',\n",
      " 'backbone': 'mobilenetv2',\n",
      " 'loss': <dl.loss.segmentation_losses.SegmentationLosses object at 0x7fbf80dc0f10>,\n",
      " 'metric': <dl.metric.segmentation_metrics.SegmentationMetrics object at 0x7fbf80dc0d10>,\n",
      " 'parent': <dl.DeepLearning.DeepLearning object at 0x7fbfcc0b9a50>,\n",
      " 'preprocessingfnc': None,\n",
      " 'pretrained': True,\n",
      " 'type': <dlMode.Segmentation: 2>}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is from the version that reads the dl object from a pkl file.\n",
    "'''\n",
    "\n",
    "print('load settings')\n",
    "#filehandler = open(modelname + '.pkl', 'rb')\n",
    "filehandler = open(pklDir + modelname + '.pkl', 'rb')\n",
    "\n",
    "dl = pickle.load(filehandler)\n",
    "print(dl.epochs)\n",
    "if epochs != 0:\n",
    "    dl.epochs = epochs\n",
    "if BackBone != None:\n",
    "    dl.Mode.backbone = BackBone\n",
    "pprint(vars(dl.Mode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run this cell if you want to save the dl object as a pkl file\n",
    "'''\n",
    "\n",
    "pklFileHandler = open(pklDir+dl.Mode.architecture+'_'+dl.Mode.backbone+'_ep'+str(dl.epochs) + '.pkl','wb')\n",
    "#import sys\n",
    "#print(sys.getrecursionlimit())\n",
    "#sys.setrecursionlimit(4*sys.getrecursionlimit())\n",
    "#print(sys.getrecursionlimit())\n",
    "\n",
    "hed = dl.hed\n",
    "dl.hed = None\n",
    "model = dl.Model\n",
    "dl.Model = None\n",
    "pickle.dump(dl, pklFileHandler)\n",
    "dl.hed = hed\n",
    "dl.Model = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsi/aryeh/git/miaHeadless/mia/dl/models/keras_applications/mobilenet_v2.py:296: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "2023-07-05 17:46:35.100066: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-05 17:46:35.116908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-05 17:46:35.161204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2023-07-05 17:46:35.161259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-05 17:46:35.234624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-05 17:46:35.234720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-05 17:46:35.269305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-05 17:46:35.368896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-05 17:46:35.422853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-05 17:46:35.444827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-05 17:46:35.505569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-05 17:46:35.508920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-05 17:46:35.510687: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 17:46:35.514441: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-05 17:46:35.515138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2023-07-05 17:46:35.515208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-05 17:46:35.515260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-05 17:46:35.515292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-05 17:46:35.515323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-05 17:46:35.515354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-05 17:46:35.515384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-05 17:46:35.515413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-05 17:46:35.515444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-05 17:46:35.520893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-05 17:46:35.520953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-05 17:46:36.571493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-05 17:46:36.571537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-05 17:46:36.571554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-05 17:46:36.581385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10264 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# pod, stem, background, and unlabeled (for deleaved soybean plants)\n",
    "numClasses =4\n",
    "\n",
    "print('init model')\n",
    "dl.initModel(numClasses)\n",
    "\n",
    "dl.Model = dl.Mode.getModel(numClasses, 3)\n",
    "\n",
    "print('load model')\n",
    "if loadweights is not None:\n",
    "    dl.Model.load_weights(loadweights)\n",
    "\n",
    "print(dl.initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 17:47:07.829014: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-07-05 17:47:07.830182: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199850000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function focal_loss.<locals>._focal_loss at 0x7fbef45be7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function focal_loss.<locals>._focal_loss at 0x7fbef45be7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 17:47:15.669780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-05 17:47:17.212518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 31s 159ms/step - loss: 0.0069 - pixel_accuracy: 194045.5169 - val_loss: 0.0621 - val_pixel_accuracy: 9219.3252\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.0054 - pixel_accuracy: 203210.4762 - val_loss: 0.0502 - val_pixel_accuracy: 54875.4492\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - 17s 124ms/step - loss: 0.0056 - pixel_accuracy: 220146.6813 - val_loss: 0.0220 - val_pixel_accuracy: 16626.6250\n",
      "Epoch 4/50\n",
      "133/133 [==============================] - 16s 112ms/step - loss: 0.0050 - pixel_accuracy: 210103.8587 - val_loss: 0.0132 - val_pixel_accuracy: 74128.5234\n",
      "Epoch 5/50\n",
      "133/133 [==============================] - 16s 115ms/step - loss: 0.0046 - pixel_accuracy: 227144.1705 - val_loss: 0.0189 - val_pixel_accuracy: 9831.0000\n",
      "Epoch 6/50\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 0.0048 - pixel_accuracy: 225589.8122 - val_loss: 0.0255 - val_pixel_accuracy: 7896.6499\n",
      "Epoch 7/50\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.0044 - pixel_accuracy: 239055.1635 - val_loss: 0.0131 - val_pixel_accuracy: 61773.8242\n",
      "Epoch 8/50\n",
      "133/133 [==============================] - 16s 113ms/step - loss: 0.0047 - pixel_accuracy: 236389.0552 - val_loss: 0.0192 - val_pixel_accuracy: 148355.7812\n",
      "Epoch 9/50\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.0044 - pixel_accuracy: 242253.8530 - val_loss: 0.0150 - val_pixel_accuracy: 145267.6562\n",
      "Epoch 10/50\n",
      "133/133 [==============================] - 15s 112ms/step - loss: 0.0042 - pixel_accuracy: 247947.0274 - val_loss: 0.0139 - val_pixel_accuracy: 116801.9766\n",
      "Epoch 11/50\n",
      "133/133 [==============================] - 18s 125ms/step - loss: 0.0043 - pixel_accuracy: 248789.5285 - val_loss: 0.0194 - val_pixel_accuracy: 43827.2266\n",
      "Epoch 12/50\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.0042 - pixel_accuracy: 256256.4946 - val_loss: 0.0128 - val_pixel_accuracy: 180431.5938\n",
      "Epoch 13/50\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.0039 - pixel_accuracy: 242828.1834 - val_loss: 0.0187 - val_pixel_accuracy: 21580.4492\n",
      "Epoch 14/50\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 0.0044 - pixel_accuracy: 241358.0262 - val_loss: 0.0120 - val_pixel_accuracy: 48996.6758\n",
      "Epoch 15/50\n",
      "133/133 [==============================] - 17s 122ms/step - loss: 0.0040 - pixel_accuracy: 246895.6199 - val_loss: 0.0114 - val_pixel_accuracy: 143125.0938\n",
      "Epoch 16/50\n",
      "133/133 [==============================] - 17s 119ms/step - loss: 0.0040 - pixel_accuracy: 243183.3155 - val_loss: 0.0061 - val_pixel_accuracy: 212291.8281\n",
      "Epoch 17/50\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0039 - pixel_accuracy: 253498.5159 - val_loss: 0.0052 - val_pixel_accuracy: 277548.3750\n",
      "Epoch 18/50\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.0039 - pixel_accuracy: 248454.1519 - val_loss: 0.0063 - val_pixel_accuracy: 242258.7969\n",
      "Epoch 19/50\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 0.0038 - pixel_accuracy: 246453.1177 - val_loss: 0.0051 - val_pixel_accuracy: 203466.5938\n",
      "Epoch 20/50\n",
      "133/133 [==============================] - 16s 113ms/step - loss: 0.0037 - pixel_accuracy: 258527.5309 - val_loss: 0.0042 - val_pixel_accuracy: 231554.4531\n",
      "Epoch 21/50\n",
      "133/133 [==============================] - 16s 119ms/step - loss: 0.0036 - pixel_accuracy: 259266.9934 - val_loss: 0.0042 - val_pixel_accuracy: 228682.8750\n",
      "Epoch 22/50\n",
      "133/133 [==============================] - 18s 121ms/step - loss: 0.0037 - pixel_accuracy: 254555.4511 - val_loss: 0.0040 - val_pixel_accuracy: 199502.2188\n",
      "Epoch 23/50\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0037 - pixel_accuracy: 264174.1805 - val_loss: 0.0040 - val_pixel_accuracy: 203766.1562\n",
      "Epoch 24/50\n",
      "133/133 [==============================] - 17s 123ms/step - loss: 0.0037 - pixel_accuracy: 251120.3589 - val_loss: 0.0036 - val_pixel_accuracy: 244618.9219\n",
      "Epoch 25/50\n",
      "133/133 [==============================] - 16s 113ms/step - loss: 0.0035 - pixel_accuracy: 260779.9669 - val_loss: 0.0038 - val_pixel_accuracy: 249082.1562\n",
      "Epoch 26/50\n",
      "133/133 [==============================] - 16s 115ms/step - loss: 0.0036 - pixel_accuracy: 263591.5538 - val_loss: 0.0038 - val_pixel_accuracy: 224001.7500\n",
      "Epoch 27/50\n",
      "133/133 [==============================] - 17s 126ms/step - loss: 0.0036 - pixel_accuracy: 261023.2448 - val_loss: 0.0040 - val_pixel_accuracy: 196909.4531\n",
      "Epoch 28/50\n",
      "133/133 [==============================] - 16s 118ms/step - loss: 0.0034 - pixel_accuracy: 267210.8351 - val_loss: 0.0040 - val_pixel_accuracy: 207708.8438\n",
      "Epoch 29/50\n",
      "133/133 [==============================] - 17s 117ms/step - loss: 0.0034 - pixel_accuracy: 261295.0612 - val_loss: 0.0043 - val_pixel_accuracy: 201628.9219\n",
      "Epoch 30/50\n",
      "133/133 [==============================] - 17s 121ms/step - loss: 0.0035 - pixel_accuracy: 264175.6992 - val_loss: 0.0033 - val_pixel_accuracy: 272041.0625\n",
      "Epoch 31/50\n",
      "133/133 [==============================] - 16s 111ms/step - loss: 0.0035 - pixel_accuracy: 262137.5721 - val_loss: 0.0034 - val_pixel_accuracy: 270251.2500\n",
      "Epoch 32/50\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 0.0035 - pixel_accuracy: 266826.6852 - val_loss: 0.0033 - val_pixel_accuracy: 272938.1875\n",
      "Epoch 33/50\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.0034 - pixel_accuracy: 259696.0189 - val_loss: 0.0033 - val_pixel_accuracy: 270522.0000\n",
      "Epoch 34/50\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 0.0035 - pixel_accuracy: 261992.8861 - val_loss: 0.0033 - val_pixel_accuracy: 278985.0312\n",
      "Epoch 35/50\n",
      "133/133 [==============================] - 16s 113ms/step - loss: 0.0035 - pixel_accuracy: 271658.0231 - val_loss: 0.0033 - val_pixel_accuracy: 277530.4375\n",
      "Epoch 36/50\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 0.0035 - pixel_accuracy: 266210.6447 - val_loss: 0.0032 - val_pixel_accuracy: 280951.1562\n",
      "Epoch 37/50\n",
      "133/133 [==============================] - 16s 117ms/step - loss: 0.0034 - pixel_accuracy: 263893.3432 - val_loss: 0.0033 - val_pixel_accuracy: 277328.1562\n",
      "Epoch 38/50\n",
      "133/133 [==============================] - 17s 119ms/step - loss: 0.0036 - pixel_accuracy: 263014.5069 - val_loss: 0.0033 - val_pixel_accuracy: 277707.9375\n",
      "Epoch 39/50\n",
      "133/133 [==============================] - 16s 114ms/step - loss: 0.0034 - pixel_accuracy: 258583.4447 - val_loss: 0.0033 - val_pixel_accuracy: 278732.9062\n",
      "Epoch 40/50\n",
      "133/133 [==============================] - 16s 120ms/step - loss: 0.0034 - pixel_accuracy: 255960.0452 - val_loss: 0.0033 - val_pixel_accuracy: 280889.1562\n",
      "Epoch 41/50\n",
      "133/133 [==============================] - 16s 115ms/step - loss: 0.0036 - pixel_accuracy: 258405.4024 - val_loss: 0.0033 - val_pixel_accuracy: 282334.8438\n",
      "Epoch 42/50\n",
      "133/133 [==============================] - 16s 122ms/step - loss: 0.0035 - pixel_accuracy: 259829.4346 - val_loss: 0.0033 - val_pixel_accuracy: 284126.5625\n",
      "Epoch 43/50\n",
      "133/133 [==============================] - 16s 111ms/step - loss: 0.0034 - pixel_accuracy: 263031.4365 - val_loss: 0.0033 - val_pixel_accuracy: 283734.7500\n",
      "Epoch 44/50\n",
      "133/133 [==============================] - 17s 125ms/step - loss: 0.0034 - pixel_accuracy: 262864.0463 - val_loss: 0.0033 - val_pixel_accuracy: 284170.4062\n",
      "Epoch 45/50\n",
      "133/133 [==============================] - 16s 116ms/step - loss: 0.0036 - pixel_accuracy: 261887.9106 - val_loss: 0.0033 - val_pixel_accuracy: 284009.2812\n",
      "Epoch 46/50\n",
      "133/133 [==============================] - 16s 114ms/step - loss: 0.0035 - pixel_accuracy: 261457.4731 - val_loss: 0.0033 - val_pixel_accuracy: 284234.3750\n",
      "Epoch 47/50\n",
      "133/133 [==============================] - 17s 118ms/step - loss: 0.0034 - pixel_accuracy: 270780.1618 - val_loss: 0.0033 - val_pixel_accuracy: 284400.0312\n",
      "Epoch 48/50\n",
      "133/133 [==============================] - 17s 117ms/step - loss: 0.0034 - pixel_accuracy: 261448.6727 - val_loss: 0.0033 - val_pixel_accuracy: 284311.0938\n",
      "Epoch 49/50\n",
      "133/133 [==============================] - 17s 124ms/step - loss: 0.0035 - pixel_accuracy: 261064.2466 - val_loss: 0.0033 - val_pixel_accuracy: 284206.6562\n",
      "Epoch 50/50\n",
      "133/133 [==============================] - 16s 113ms/step - loss: 0.0034 - pixel_accuracy: 261053.7913 - val_loss: 0.0033 - val_pixel_accuracy: 284510.6875\n",
      "training finished\n",
      "saving weights\n",
      "model path:  /home/dsi/aryeh/data/mia/trained_models/UNet_mobilenetv2_ep50.h5\n",
      "saving training data\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here we  do the training\n",
    "'''\n",
    "        \n",
    "if dl.initialized:\n",
    "    print('start training')\n",
    "    dl.initData_StartTraining(trainingdata, validationdata)\n",
    "    print('training finished')\n",
    "else:\n",
    "    print('could not initialize model')\n",
    "            \n",
    "print('saving weights')\n",
    "modelname=dl.Mode.architecture+'_'+dl.Mode.backbone\n",
    "modelPath = modelDir+modelname+'_ep'+str(dl.epochs) + '.h5'\n",
    "print('model path: ', modelPath)\n",
    "dl.Model.save_weights(modelPath)\n",
    "print('saving training data')\n",
    "dl.saveTrainingRecord(modelDir+modelname+'_ep'+str(dl.epochs) +'.csv')\n",
    "#   print('saving model')\n",
    "#   dl.Model.save(modelDir+'full')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell does a prediction on a directory of jpg images (could be any type, but that is what I have).\n",
    "predictionFolder contains the images which ill be predicted, and a subdirectory with the modelname will be created\n",
    "to hold the predicted segmentation.\n",
    "\n",
    "A h5 file with pretrained weights can be loaded, in which case the traiing step above can be skipped.\n",
    "However, the previous cells tha set up the dl object must be run. I have not yet succeeded in defining \n",
    "a properly working dl object wihtout first usin a saved pkl file.\n",
    "\n",
    "To use the model that was just trained, press \"cancel\" when prompted for a weights file.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "modelWeightsPath = fd.askopenfilename(\n",
    "        title='Open a weights file (h5)',\n",
    "        initialdir=modelDir)\n",
    "\n",
    "print(modelWeightsPath)\n",
    "\n",
    "if modelWeightsPath != \"\":\n",
    "    dl.Model.load_weights(modelWeightsPath)\n",
    "\n",
    "predictionFolder = fd.askdirectory(initialdir=predictionFolder) + os.sep\n",
    "outputPath = predictionFolder + modelname+'_ep'+str(dl.epochs)+'/'\n",
    "try:\n",
    "    os.mkdir(outputPath)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "files = glob.glob(predictionFolder + '*.jpg')\n",
    "print(len(files))\n",
    "\n",
    "\n",
    "\n",
    "# If we do not want to process the entire folder, we can limit the number of processed image to count. \n",
    "# If the entire folder is processed, then it wold be agood idea to comment out the image display \n",
    "count = 0\n",
    "for i in files:\n",
    "    print(i)\n",
    "    img = cv2.imread(i)\n",
    "    prediction = dl.Mode.PredictImage(img)\n",
    "    plt.figure(count)\n",
    "    plt.imshow(prediction)\n",
    "    plt.show()\n",
    "    cv2.imwrite(outputPath+'segmented_'+os.path.basename(i).replace('jpg', 'png'), prediction)\n",
    "    count += 1\n",
    "#    if count > 10:\n",
    "#       break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictionFolder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
