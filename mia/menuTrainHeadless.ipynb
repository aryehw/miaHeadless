{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is meant to run mianalyzer headless. Mianalyzer is a code that can run a variety of neural network architrecture and backbones, without the user having to define them himeself. It normally runs as a GUI application. However, when run on a remote server, the GUI version is much too slow,  The mianalyzer author (koerber) kindly provided a python script to run the training sequence  headless, after loading a \"pickled\"dl object from a pkl file. \n",
    "\n",
    "Inputs:\n",
    "    1. Directory that holds the pkl file\n",
    "    2. Directory where the model will be saved\n",
    "    3. The name of the saved pkl file (the pkl extensionis assumed)\n",
    "    4. The directory containing the training data. The Segmentation_labels subdiretory must also be present.\n",
    "    5. The prediction folder containing images on which the trained model will be tested. \n",
    "    6. model backbone (default is densenet201)\n",
    "    7. number of epochs (default defined in the pkl file)\n",
    "\n",
    " Outputs:\n",
    "    1. The dl object that will be used to train the model\n",
    "    2. The trained model (a .h5 file, and a .csv file with the loss history)\n",
    "    3. A subdirectory that will hold the segmented images.\n",
    "\n",
    "This Jupyter script is based on code provided by mianalzer author Nils Koerber (nils.koerber@bfr.bund.de)\n",
    "\n",
    "Modifed by Aryeh Weiss\n",
    "Last modified: 19 June 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the script usees tkinter to prompt for teh various directories and files that are needed.\n",
    "The defaults are the same, and cliking ok will select default values.\n",
    "When run on a remote GPU server, this version will be slower because it opens X windows on the local machine,\n",
    "over the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog as fd\n",
    "\n",
    "from tensorflow.config import list_physical_devices # To see if we're using GPU\n",
    "# Making sure we're using GPU\n",
    "print(list_physical_devices())\n",
    "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
    "\n",
    "# select one of the multiple GPU cards on the server.\n",
    "gpuNumber = input(\"Select GPU or enter for 0\\n\") or '0'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpuNumber  # set GPU if multiple present\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code is developed and run on at least two machines\n",
    "Here we setup the default paths for each machine.\n",
    "Eventually we must find a more general way to do this.\n",
    "'''\n",
    "\n",
    "host = os.getenv('HOSTNAME')\n",
    "if host==None:      # pop os dees not have HOSTNAME defined by default.\n",
    "    host = \"pop\"\n",
    "print(host)\n",
    "\n",
    "if \"dsigpu\" in host:\n",
    "    pklDir = '/home/dsi/aryeh/data/mia/pkl/'\n",
    "    modelDir = '/home/dsi/aryeh/data/mia/trained_models/'\n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata = '/home/dsi/aryeh/data/plants/unCropped/resized/'\n",
    "    predictionFolder = '/home/dsi/aryeh/data/plants/Harvest8Orange5_7Oct17/'\n",
    "    os.environ['DISPLAY']='localhost:10.0'\n",
    "\n",
    "elif \"pop\" in host:\n",
    "    pklDir = '/media/amw/TOSHIBA EXT/alerding/models/pkl/'\n",
    "    modelDir = '/media/amw/TOSHIBA EXT/alerding/models/gpuModels/'\n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata =  '/media/amw/TOSHIBA EXT/alerding/annotated/trainingSet/'\n",
    "    predictionFolder = '/media/amw/TOSHIBA EXT/alerding/Harvest 8 Orange 5,7 Oct 17.r/vertical/'\n",
    "else:\n",
    "    pklDir = None\n",
    "    modelDir = None \n",
    "    modelname = \"unetDensnet201_2023-01-24_08-17-37\"\n",
    "    trainingdata = None\n",
    "    predictionFolder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Put this in a separate cell so that multiple instances of Tk are not invoked\n",
    "'''\n",
    "root = Tk()\n",
    "root.withdraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pklDir = fd.askdirectory(title = \"select pkl directory\",initialdir=pklDir) + os.sep\n",
    "modelDir = fd.askdirectory(title = \"select model directory\", initialdir=modelDir) + os.sep\n",
    "trainingdata = fd.askdirectory(title = \"select training directory\",initialdir=trainingdata) + os.sep\n",
    "predictionFolder = fd.askdirectory(title = \"select prediction directory\", initialdir=predictionFolder) + os.sep\n",
    "\n",
    "\n",
    "\n",
    "modelFilePath = fd.askopenfilename(\n",
    "        title='Open a pkl file',\n",
    "        initialdir=pklDir)\n",
    "\n",
    "filename = os.path.basename(modelFilePath)\n",
    "modelname = os.path.splitext(filename)[0]\n",
    "\n",
    "print(\"model: \", modelname)\n",
    "\n",
    "validationdata = None\n",
    "\n",
    "loadweights = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set the window geometry\n",
    "root.geometry(\"200x200\")\n",
    "root.deiconify()\n",
    "\n",
    "# Create object\n",
    "# root = Tk()\n",
    "\n",
    "# Adjust size\n",
    "# root.geometry( \"200x200\" )\n",
    "\n",
    "# Change the label text\n",
    "def show():\n",
    "\tlabel.config( text = clicked.get() )\n",
    "\n",
    "# list of backbones\n",
    "backbones = [None, 'resnet18', 'resnet34','resnet50', 'resnet101', 'resnet152',\n",
    "             'seresnet18', 'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', 'seresnext101',\n",
    "             'senet154','resnext50', 'resnext101', 'vgg16', 'vgg19',\n",
    "             'densenet121', 'densenet169', 'densenet201', 'inceptionresnetv2', 'inceptionv3',\n",
    "             'mobilenet', 'mobilenetv2',\n",
    "             'efficientnetb0','efficientnetb1','efficientnetb02','efficientnetb3','efficientnetb4','efficientnetb5','efficientnetb6','efficientnetb7']\n",
    "\n",
    "# datatype of menu text\n",
    "clicked = StringVar()\n",
    "\n",
    "# Create Dropdown menu\n",
    "drop = OptionMenu( root , clicked , *backbones )\n",
    "drop.pack()\n",
    "\n",
    "# Create Label\n",
    "label = Label( root , text = \"Choose backbone\" )\n",
    "label.pack()\n",
    "\n",
    "Button(root, text=\"Quit\", command=root.destroy).pack() \n",
    "  \n",
    "# Execute tkinter\n",
    "root.mainloop()\n",
    "\n",
    "BackBone = clicked.get()\n",
    "print(BackBone)\n",
    "\n",
    "strEpochs = input(\"input number of epochs or enter to use the predefined value in a pkl file\\n\") or '0'\n",
    "epochs = int(strEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is from the version that reads the dl object from a pkl file.\n",
    "'''\n",
    "\n",
    "print('load settings')\n",
    "#filehandler = open(modelname + '.pkl', 'rb')\n",
    "filehandler = open(pklDir + modelname + '.pkl', 'rb')\n",
    "\n",
    "dl = pickle.load(filehandler)\n",
    "\n",
    "if epochs != 0:\n",
    "    dl.epochs = epochs\n",
    "if BackBone != None:\n",
    "    dl.Mode.backbone = BackBone\n",
    "pprint(vars(dl.Mode))\n",
    "print(dl.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run this cell if you want to save the dl object as a pkl file\n",
    "'''\n",
    "\n",
    "pklFileHandler = open(pklDir+dl.Mode.architecture+'_'+dl.Mode.backbone+'_ep'+str(dl.epochs) + '.pkl','wb')\n",
    "#import sys\n",
    "#print(sys.getrecursionlimit())\n",
    "#sys.setrecursionlimit(4*sys.getrecursionlimit())\n",
    "#print(sys.getrecursionlimit())\n",
    "\n",
    "hed = dl.hed\n",
    "dl.hed = None\n",
    "model = dl.Model\n",
    "dl.Model = None\n",
    "pickle.dump(dl, pklFileHandler)\n",
    "dl.hed = hed\n",
    "dl.Model = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pod, stem, background, and unlabeled (for deleaved soybean plants)\n",
    "numClasses =4\n",
    "\n",
    "print('init model')\n",
    "dl.initModel(numClasses)\n",
    "\n",
    "dl.Model = dl.Mode.getModel(numClasses, 3)\n",
    "\n",
    "print('load model')\n",
    "if loadweights is not None:\n",
    "    dl.Model.load_weights(loadweights)\n",
    "\n",
    "print(dl.initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we  do the training\n",
    "'''\n",
    "        \n",
    "if dl.initialized:\n",
    "    print('start training')\n",
    "    dl.initData_StartTraining(trainingdata, validationdata)\n",
    "    print('training finished')\n",
    "else:\n",
    "    print('could not initialize model')\n",
    "            \n",
    "print('saving weights')\n",
    "modelname=dl.Mode.architecture+'_'+dl.Mode.backbone\n",
    "modelPath = modelDir+modelname+'_ep'+str(dl.epochs) + '.h5'\n",
    "print('model path: ', modelPath)\n",
    "dl.Model.save_weights(modelPath)\n",
    "print('saving training data')\n",
    "dl.saveTrainingRecord(modelDir+modelname+'_ep'+str(dl.epochs) +'.csv')\n",
    "#   print('saving model')\n",
    "#   dl.Model.save(modelDir+'full')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell does a prediction on a directory of jpg images (could be any type, but that is what I have).\n",
    "predictionFolder contains the images which ill be predicted, and a subdirectory with the modelname will be created\n",
    "to hold the predicted segmentation.\n",
    "\n",
    "A h5 file with pretrained weights can be loaded, in which case the traiing step above can be skipped.\n",
    "However, the previous cells tha set up the dl object must be run. I have not yet succeeded in defining \n",
    "a properly working dl object wihtout first usin a saved pkl file.\n",
    "\n",
    "To use the model that was just trained, press \"cancel\" when prompted for a weights file.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "modelWeightsPath = fd.askopenfilename(\n",
    "        title='Open a weights file (h5)',\n",
    "        initialdir=modelDir)\n",
    "\n",
    "print(modelWeightsPath)\n",
    "\n",
    "if modelWeightsPath != \"\":\n",
    "    dl.Model.load_weights(modelWeightsPath)\n",
    "\n",
    "predictionFolder = fd.askdirectory(initialdir=predictionFolder) + os.sep\n",
    "outputPath = predictionFolder + modelname+'_ep'+str(dl.epochs)+'/'\n",
    "try:\n",
    "    os.mkdir(outputPath)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "files = glob.glob(predictionFolder + '*.jpg')\n",
    "print(len(files))\n",
    "\n",
    "\n",
    "\n",
    "# If we do not want to process the entire folder, we can limit the number of processed image to count. \n",
    "# If the entire folder is processed, then it wold be agood idea to comment out the image display \n",
    "count = 0\n",
    "for i in files:\n",
    "    print(i)\n",
    "    img = cv2.imread(i)\n",
    "    prediction = dl.Mode.PredictImage(img)\n",
    "    plt.figure(count)\n",
    "    plt.imshow(prediction)\n",
    "    plt.show()\n",
    "    cv2.imwrite(outputPath+'segmented_'+os.path.basename(i).replace('jpg', 'png'), prediction)\n",
    "    count += 1\n",
    "#    if count > 10:\n",
    "#       break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictionFolder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
